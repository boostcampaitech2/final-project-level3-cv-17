{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Usage"]},{"cell_type":"markdown","metadata":{},"source":["1. 해당 분류의 img path를 img_root에 넣는다.\n","2. 몇 개의 class만 확인하고 싶은 경우 classes에 확인 하고 싶은 소분류 class를 넣는다.\n","3. imgs에 너무 많은 image가 들어간 경우 random.choices(imgs, k=?)로 대충 sampling해서 돌린다.\n","4. batch size는 16이상으로 지정하는 것이 좋다.\n","5. epoch은 20~30만해도 될 것 같다."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 72/72 [00:42<00:00,  1.68it/s]\n"]}],"source":["import os\n","from os.path import splitext, join\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","\n","img_root = r'/opt/ml/data/stew/train'\n","# label_root = r'/opt/ml/data/labels/train'\n","\n","# for img_path in os.listdir(img_root):\n","#     imgs.append(join(img_root, img_path))\n","\n","classes = [\n","# '02011019',\n","# '02011038',\n","# '02011039',\n","# '04011001',\n","# '04011002',\n","# '04011003',\n","# '04011004',\n","# '04011005',\n","# '04011006',\n","# '04011007',\n","# '04011008',\n","# '04011010',\n","# '04011011',\n","# '04011012',\n","# '04011013',\n","# '04011014',\n","# '04011015',\n","# '04011016',\n","# '04012001',\n","# '04012002',\n","# '04012003',\n","# '04012004',\n","# '04012005',\n","# '04012006',\n","# '04012007',\n","# '04012008',\n","# '04012009',\n","# '04012010',\n","# '04012011',\n","# '04012012',\n","# '04012013',\n","# '04013002',\n","# '04013003',\n","# '04013004',\n","# '04013005',\n","# '04013006',\n","# '04013007',\n","# '04013008',\n","# '04013009',\n","# '04013010',\n","# '04013011',\n","# '04013012',\n","# '04013013',\n","# '04013014',\n","# '04013015',\n","# '04013017',\n","# '04013018',\n","# '04013019',\n","# '04013020',\n","# '04013021',\n","# '04013022',\n","# '04013023',\n","# '04013024',\n","# '04014001',\n","'04015001',\n","'04015002',\n","'04015003',\n","'04016001',\n","'04017001',\n","'04017002',\n","'04018001',\n","'04018002',\n","'04018003',\n","'04018004',\n","'04019001',\n","'04019002',\n","'04019003',\n","'04019004',\n","'04019005',\n","'04019006',\n","'04019007',\n","'04019008'\n","]\n","\n","imgs = []\n","labels = []\n","\n","# -- label data 2 dataframe & xywh 2 xyxy\n","df = pd.DataFrame([], columns=['class', 'mean1', 'mean2', 'mean3', 'std1', 'std2', 'std3'])\n","\n","img_dirs = os.listdir(img_root)\n","for img_dir in tqdm(img_dirs):\n","    for img_file in os.listdir(join(img_root, img_dir)):\n","        filename = splitext(img_file)[0]\n","\n","        small_label = filename.split('_')[2]\n","        if small_label not in classes:\n","            continue\n","        labels.append(int(small_label))\n","        imgs.append(np.array(Image.open(join(img_root, img_dir, img_file))))"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["28725\n","28725\n","18\n"]}],"source":["print(len(imgs))\n","print(len(labels))\n","num_classes = len(np.unique(labels))\n","print(num_classes)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import torch\n","import random\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from torchvision.transforms import *\n","\n","class TripletDataset(Dataset):\n","    def __init__(self, img_paths, labels, train=True):\n","        self.img_paths = np.array(img_paths)\n","        self.labels = np.array(labels)\n","        self.transform = transforms.Compose([\n","            ToTensor(),\n","            Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n","        ])\n","        self.train = train\n","\n","    def __getitem__(self, idx: torch.Tensor) -> torch.Tensor:\n","        anchor_img, anchor_label = self.img_paths[idx], self.labels[idx]\n","        if self.transform:\n","            anchor_img = self.transform(anchor_img)\n","\n","        if self.train:\n","            positive_idx = np.where(self.labels == anchor_label)[0]\n","            positive_idx = [p_idx for p_idx in positive_idx if p_idx != idx] # anchor index 제외\n","            negative_idx = np.where(self.labels != anchor_label)[0]\n","\n","            positive_img = self.img_paths[random.choice(positive_idx)]\n","            negative_img = self.img_paths[random.choice(negative_idx)]\n","\n","            if self.transform:\n","                positive_img = self.transform(positive_img)\n","                negative_img = self.transform(negative_img)\n","            \n","            return anchor_img, positive_img, negative_img, anchor_label\n","\n","        return anchor_img, anchor_label\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","\n","class TripletLoss(nn.Module):\n","    '''\n","    Compute normal triplet loss or soft margin triplet loss given triplets\n","    '''\n","    def __init__(self, margin = None):\n","        super(TripletLoss, self).__init__()\n","        self.margin = margin\n","        if self.margin is None:  # use soft-margin\n","            self.Loss = nn.SoftMarginLoss()\n","        else:\n","            self.Loss = nn.TripletMarginLoss(margin = margin, p = 2)\n","\n","    def forward(self, anchor, pos, neg):\n","        if self.margin is None:\n","            num_samples = anchor.shape[0]\n","            y = torch.ones((num_samples, 1)).view(-1)\n","            if anchor.is_cuda: y = y.cuda()\n","            ap_dist = torch.norm(anchor - pos, 2, dim = 1).view(-1)\n","            an_dist = torch.norm(anchor - neg, 2, dim = 1).view(-1)\n","            loss = self.Loss(an_dist - ap_dist, y)\n","        else:\n","            loss = self.Loss(anchor, pos, neg)\n","\n","        return loss"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n"]}],"source":["from torch.utils.data import DataLoader\n","from efficientnet_pytorch import EfficientNet\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","import multiprocessing\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","train_set = TripletDataset(imgs, labels)\n","dataloader = DataLoader(train_set,\n","                        batch_size=16,\n","                        num_workers=multiprocessing.cpu_count()//2,\n","                        shuffle=False,\n","                        pin_memory=use_cuda)\n","model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=num_classes)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","lr_scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-4)\n","criterion = TripletLoss(margin=2.0)\n","NUM_EPOCH = 30"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1796/1796 [09:08<00:00,  3.27it/s]"]},{"name":"stdout","output_type":"stream","text":["loss:  0.0 epoch:  0\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["model = model.to(device)\n","\n","for epoch in range(NUM_EPOCH):\n","    losses = []\n","    \n","    model.train()\n","    for idx, (anchor_img, positive_img, negative_img, anchor_label) in enumerate(tqdm(dataloader)):\n","        anchor_img = anchor_img.to(device)\n","        positive_img = positive_img.to(device)\n","        negative_img = negative_img.to(device)\n","        anchor_label = anchor_label.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        a_embeds = model(anchor_img)\n","        p_embeds = model(positive_img)\n","        n_embeds = model(negative_img)\n","\n","        loss = criterion(a_embeds, p_embeds, n_embeds)\n","\n","        loss.backward()\n","        optimizer.step()\n","        lr_scheduler.step()\n","        \n","        losses.append(loss.item())\n","    print('loss: ', loss.item(), 'epoch: ', epoch)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1796/1796 [00:55<00:00, 32.53it/s]\n"]}],"source":["train_results = []\n","labels = []\n","\n","model.eval()\n","\n","with torch.no_grad():\n","    for img, _, _, label in tqdm(dataloader):\n","        img = img.to(device)\n","        label = label.to(device)\n","        train_results.append(model(img).detach().cpu().numpy())\n","        labels.append(label.detach().cpu().numpy())\n","\n","train_results = np.concatenate(train_results)\n","labels = np.concatenate(labels)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from matplotlib import colors as mcolors\n","import random\n","colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n","color_key = list(colors.keys())\n","\n","use_colors = [colors[color_key[i]] for i in range(num_classes)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.graph_objects as go\n","import plotly.io as pio\n","pio.renderers.default = \"vscode\"\n","\n","import numpy as np\n","data = []\n","for idx, label in enumerate(np.unique(labels)[:]):\n","    tmp = train_results[np.where(labels == label)[0]]\n","    data.append(go.Scatter3d(x=tmp[:, 1], y=tmp[:, 0], z=tmp[:, 2], mode='markers', marker=dict(size=2), name=str(label)))\n","fig = go.Figure(data=data)\n","fig.update_layout(\n","    autosize=False,\n","    width=1000,\n","    height=1000,\n","    )\n","fig.show()"]}],"metadata":{"interpreter":{"hash":"e31c68abf1d5dd3f9e2269f23eadf1b199587e56c0618a30760176a65ebfcab4"},"kernelspec":{"display_name":"Python 3.7.11 64-bit ('lightweight': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
